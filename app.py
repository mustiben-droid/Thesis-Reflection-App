import json, base64, os, io, time, pandas as pd, streamlit as st
import google.generativeai as genai
from google.oauth2.service_account import Credentials
from googleapiclient.discovery import build
from googleapiclient.http import MediaIoBaseUpload, MediaIoBaseDownload
from datetime import date, datetime

# --- 专转 ---
DATA_FILE = "reflections.jsonl"
MASTER_FILENAME = "All_Observations_Master.xlsx"
CLASS_ROSTER = ["转", "专注", "住祝", "注", "", "", "驻拽", ".专", "", "专", "驻.拽", "转 专..."]

st.set_page_config(page_title="注专转 转爪驻转 - 61.0", layout="wide")

# --- 驻拽爪转 拽 专住转 (住住 注  拽抓 砖) ---
def clean_research_data(df):
    if df is None or df.empty:
        return pd.DataFrame()
    
    # 1. 砖专转 注转 专转   注 驻转 拽住 砖
    essential_cols = [
        'date', 'student_name', 'challenge', 'interpretation', 'timestamp',
        'cat_convert_rep', 'cat_proj_trans', 'cat_self_efficacy', 'work_method', 'exercise_difficulty'
    ]
    
    # 拽  注转 拽转 ( 驻注 拽住 砖  score_conv)
    rename_dict = {
        'score_conv': 'cat_convert_rep',
        'score_proj': 'cat_proj_trans',
        'score_efficacy': 'cat_self_efficacy'
    }
    df = df.rename(columns=rename_dict)
    
    # 住 专拽 砖  砖拽 专
    existing_cols = [c for c in essential_cols if c in df.columns]
    df = df[existing_cols].copy()
    
    # 2. 住专转 砖专转 专拽转 专
    df = df.dropna(subset=['student_name', 'date'], how='all')
    
    # 3. 驻住 拽住 住驻
    df = df.reset_index(drop=True)
    return df

@st.cache_resource
def get_drive_svc():
    try:
        b64 = st.secrets.get("GDRIVE_SERVICE_ACCOUNT_B64")
        creds = Credentials.from_service_account_info(
            json.loads(base64.b64decode(b64).decode("utf-8")), 
            scopes=["https://www.googleapis.com/auth/drive"]
        )
        return build("drive", "v3", credentials=creds)
    except: return None

def load_all_data(svc):
    df_d = pd.DataFrame()
    if svc:
        try:
            res = svc.files().list(q=f"name = '{MASTER_FILENAME}' and trashed = false").execute().get('files', [])
            if res:
                fh = io.BytesIO()
                downloader = MediaIoBaseDownload(fh, svc.files().get_media(fileId=res[0]['id']))
                done = False
                while not done: _, done = downloader.next_chunk()
                fh.seek(0)
                df_d = pd.read_excel(fh)
                df_d = clean_research_data(df_d)
        except: pass

    df_l = pd.DataFrame()
    if os.path.exists(DATA_FILE):
        try:
            with open(DATA_FILE, "r", encoding="utf-8") as f:
                df_l = pd.DataFrame([json.loads(l) for l in f if l.strip()])
                df_l = clean_research_data(df_l)
        except: pass

    if df_d.empty: return df_l
    if df_l.empty: return df_d
    
    try:
        combined = pd.concat([df_d, df_local], axis=0, ignore_index=True)
        return clean_research_data(combined)
    except: return df_d

def get_ai_analysis(mode, ctx):
    try:
        genai.configure(api_key=st.secrets["GOOGLE_API_KEY"], transport='rest')
        model = genai.GenerativeModel('gemini-1.5-flash')
        prompt = f"转 转 {ctx['name']}:\n{str(ctx['history'])[:3500]}\n砖: {ctx.get('q', '住 转')}"
        return model.generate_content(prompt).text
    except: return "-AI   专注"

# --- 砖拽 ---
svc = get_drive_svc()
df = load_all_data(svc)

st.title(" 注专转 转爪驻转 拽专 - 专住 61.0")
tab1, tab2, tab3 = st.tabs([" ", " 住专", " 转"])

with tab1:
    col1, col2 = st.columns([1, 1])
    with col1:
        name = st.selectbox("专 住", CLASS_ROSTER)
        s1 = st.slider("专 (1-5)", 1, 5, 3)
        s2 = st.slider(" (1-5)", 1, 5, 3)
        ch = st.text_area("转专 转爪驻转")
        if st.button(" 砖专 转爪驻转"):
            if ch:
                entry = {
                    "date": date.today().isoformat(), "student_name": name, 
                    "challenge": ch, "cat_convert_rep": s1, "cat_proj_trans": s2, 
                    "timestamp": datetime.now().isoformat()
                }
                with open(DATA_FILE, "a", encoding="utf-8") as f:
                    f.write(json.dumps(entry, ensure_ascii=False) + "\n")
                st.success("砖专!"); time.sleep(0.5); st.rerun()

with tab2:
    if st.button(" 住专 专"):
        if os.path.exists(DATA_FILE):
            with st.spinner("注 转..."):
                with open(DATA_FILE, "r", encoding="utf-8") as f: l_ = [json.loads(l) for l in f if l.strip()]
                final = pd.concat([df, pd.DataFrame(l_)], ignore_index=True).drop_duplicates(subset=['student_name', 'timestamp'], keep='last')
                buf = io.BytesIO()
                with pd.ExcelWriter(buf, engine='openpyxl') as w: final.to_excel(w, index=False)
                buf.seek(0)
                res = svc.files().list(q=f"name = '{MASTER_FILENAME}'").execute().get('files', [])
                media = MediaIoBaseUpload(buf, mimetype="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")
                if res: svc.files().update(fileId=res[0]['id'], media_body=media).execute()
                else: svc.files().create(body={'name': MASTER_FILENAME}, media_body=media).execute()
                os.remove(DATA_FILE); st.success("住专 爪!"); st.rerun()

with tab3:
    if not df.empty:
        mode = st.radio("专 转:", ["砖", " 专"], horizontal=True)
        if mode == "砖":
            sel = st.selectbox("住", df['student_name'].unique())
            sd = df[df['student_name'] == sel].sort_values('date')
            st.line_chart(sd.set_index('date')[['cat_convert_rep', 'cat_proj_trans']])
            q = st.text_input(" 转专爪 砖 转 -AI?")
            if st.button("驻拽 转转"):
                st.info(get_ai_analysis("chat", {"name": sel, "history": sd.to_string(), "q": q}))
        else:
            d = st.selectbox("转专", sorted(df['date'].unique(), reverse=True))
            day_df = df[df['date'] == d]
            st.write(f"爪注  {d}:")
            st.dataframe(day_df.mean(numeric_only=True))
            if st.button("转 转  转"):
                st.success(get_ai_analysis("daily", {"name": "转", "history": day_df.to_string()}))
